{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reload the data, create the adv for G_11, Test for all model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "from __future__ import unicode_literals\n",
    "\n",
    "import keras\n",
    "import numpy as np\n",
    "import os\n",
    "from six.moves import xrange\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import app\n",
    "from tensorflow.python.platform import flags\n",
    "\n",
    "from cleverhans.utils_mnist import data_mnist\n",
    "from cleverhans.utils_tf import model_train, model_eval, batch_eval\n",
    "\n",
    "from cleverhans.attacks import fgsm\n",
    "from cleverhans.attacks_tf import jacobian_graph\n",
    "from cleverhans.utils import other_classes, cnn_model, pair_visual, grid_visual\n",
    "from Gnet import G_10,G_11,G_12,G_13\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "FLAGS = flags.FLAGS\n",
    "flags.DEFINE_integer('nb_epochs', 6, 'Number of epochs to train model')\n",
    "flags.DEFINE_integer('batch_size', 128, 'Size of training batches')\n",
    "flags.DEFINE_float('learning_rate', 0.1, 'Learning rate for training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created TensorFlow session and set Keras backend.\n",
      "X_train shape: (60000, 28, 28, 1)\n",
      "60000 train samples\n",
      "10000 test samples\n",
      "Loaded MNIST test data.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "# Set TF random seed to improve reproducibility\n",
    "tf.set_random_seed(1234)\n",
    "\n",
    "###########################################################################\n",
    "# Define the dataset and model\n",
    "###########################################################################\n",
    "\n",
    "# Image dimensions ordering should follow the Theano convention\n",
    "if keras.backend.image_dim_ordering() != 'tf':\n",
    "    keras.backend.set_image_dim_ordering('tf')\n",
    "    print(\"INFO: '~/.keras/keras.json' sets 'image_dim_ordering' \"\n",
    "          \"to 'th', temporarily setting to 'tf'\")\n",
    "\n",
    "# Create TF session and set as Keras backend session\n",
    "sess = tf.Session()\n",
    "keras.backend.set_session(sess)\n",
    "print(\"Created TensorFlow session and set Keras backend.\")\n",
    "\n",
    "# Get MNIST test data\n",
    "X_train, Y_train, X_test, Y_test = data_mnist()\n",
    "print(\"Loaded MNIST test data.\")\n",
    "\n",
    "# Define input TF placeholder\n",
    "x = tf.placeholder(tf.float32, shape=(None, 28, 28, 1))\n",
    "y = tf.placeholder(tf.float32, shape=(None, 10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined TensorFlow model graph.\n",
      "INFO:tensorflow:Restoring parameters from /home/boyuan/Documents/research/Advesarial_examples/Project/store/G11_adv/G11_advmodel\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# restore G_11_adv_trained model\n",
    "###########################################################################\n",
    "# save_path = os.path.join(FLAGS.train_dir, FLAGS.filename)\n",
    "# Define TF model graph\n",
    "model = G_11()\n",
    "predictions_1_adv = model(x)\n",
    "\n",
    "print(\"Defined TensorFlow model graph.\")\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "save_path = '/home/boyuan/Documents/research/Advesarial_examples/Project/store/G11_adv/G11_advmodel'\n",
    "#save_path3 = '/home/boyuan/Documents/research/Advesarial_examples/Project/store/G10/G10model'\n",
    "saver.restore(sess, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined TensorFlow model graph.\n",
      "INFO:tensorflow:Restoring parameters from /home/boyuan/Documents/research/Advesarial_examples/Project/store/G11/G11model\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# restore G_11 model\n",
    "###########################################################################\n",
    "# save_path = os.path.join(FLAGS.train_dir, FLAGS.filename)\n",
    "# Define TF model graph\n",
    "model = G_11()\n",
    "predictions_1 = model(x)\n",
    "\n",
    "print(\"Defined TensorFlow model graph.\")\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "save_path = '/home/boyuan/Documents/research/Advesarial_examples/Project/store/G11/G11model'\n",
    "#save_path3 = '/home/boyuan/Documents/research/Advesarial_examples/Project/store/G10/G10model'\n",
    "saver.restore(sess, save_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined TensorFlow model graph.\n",
      "INFO:tensorflow:Restoring parameters from /home/boyuan/Documents/research/Advesarial_examples/Project/store/G10/G10model\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# restore G_10 model\n",
    "###########################################################################\n",
    "# Define TF model graph\n",
    "model_0 = G_10()\n",
    "predictions_0 = model_0(x)\n",
    "\n",
    "print(\"Defined TensorFlow model graph.\")\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "save_path = '/home/boyuan/Documents/research/Advesarial_examples/Project/store/G10/G10model'\n",
    "#save_path3 = '/home/boyuan/Documents/research/Advesarial_examples/Project/store/G10/G10model'\n",
    "saver.restore(sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined TensorFlow model graph.\n",
      "INFO:tensorflow:Restoring parameters from /home/boyuan/Documents/research/Advesarial_examples/Project/store/G12/G12model\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# restore G_12 model\n",
    "###########################################################################\n",
    "# Define TF model graph\n",
    "model_2 = G_12()\n",
    "predictions_2 = model_2(x)\n",
    "\n",
    "print(\"Defined TensorFlow model graph.\")\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "save_path = '/home/boyuan/Documents/research/Advesarial_examples/Project/store/G12/G12model'\n",
    "#save_path3 = '/home/boyuan/Documents/research/Advesarial_examples/Project/store/G10/G10model'\n",
    "saver.restore(sess, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defined TensorFlow model graph.\n",
      "INFO:tensorflow:Restoring parameters from /home/boyuan/Documents/research/Advesarial_examples/Project/store/G13/G13model\n"
     ]
    }
   ],
   "source": [
    "###########################################################################\n",
    "# restore G_13 model\n",
    "###########################################################################\n",
    "# Define TF model graph\n",
    "model_3 = G_13()\n",
    "predictions_3 = model_3(x)\n",
    "\n",
    "print(\"Defined TensorFlow model graph.\")\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "save_path = '/home/boyuan/Documents/research/Advesarial_examples/Project/store/G13/G13model'\n",
    "#save_path3 = '/home/boyuan/Documents/research/Advesarial_examples/Project/store/G10/G10model'\n",
    "saver.restore(sess, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## creating the adversarial examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.create the adv from G_11 net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Craft adversarial examples using Fast Gradient Sign Method (FGSM)\n",
    "adv_x = fgsm(x, predictions_1, eps=0.3)\n",
    "eval_params = {'batch_size': FLAGS.batch_size}\n",
    "X_test_adv, = batch_eval(sess, [x], [adv_x], [X_test], args=eval_params)\n",
    "assert X_test_adv.shape[0] == 10000, X_test_adv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 28, 28, 1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_adv.shape\n",
    "adv_diff = X_test_adv - X_test\n",
    "# calculate the disturbation\n",
    "adv_diff.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0451\n"
     ]
    }
   ],
   "source": [
    "# test the accuracy with G_11\n",
    "accuracy = model_eval(sess, x, y, predictions_1, X_test_adv, Y_test,\n",
    "                          args=eval_params)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.pack the adv_G11 for testing all the networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "pickle_file = 'adv_G11.pickle'\n",
    "\n",
    "try:\n",
    "    f = open(pickle_file, 'wb')\n",
    "    save = {\n",
    "        'adv_dataset': X_test_adv,\n",
    "        'test_labels': Y_test,\n",
    "        }\n",
    "    pickle.dump(save, f, pickle.HIGHEST_PROTOCOL)\n",
    "    f.close()\n",
    "except Exception as e:\n",
    "    print('Unable to save data to', pickle_file, ':', e)\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reload the file for other model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. reload from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set (10000, 28, 28, 1) (10000, 10)\n"
     ]
    }
   ],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "pickle_file = 'adv_G11.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    adv_dataset = save['adv_dataset']\n",
    "    adv_labels = save['test_labels']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Test set', adv_dataset.shape, adv_labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAACFCAYAAABL2gNbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAC2pJREFUeJzt3UtoFM0WwPGO+RaCuPIREXwmGHFjVNRdfKG4UAmoqEjQ\niMQXKsaNGBQVDBIhuDAxChoDBtxEMYssBImIIGhcuDEQEaL4QHwRlQgRzV1cvrpVdZ1Od093Tc+Z\n/291mprprmmdQ89JPYpGRkY8AED+G5PrDgAA4kFCBwAhSOgAIAQJHQCEIKEDgBAkdAAQgoQOAEKQ\n0AFACBI6AAjxj8uLFRUVGdNSd+7cqeLr16+77IovvV+2uPrpdw0X2traimI8nfHvWlT0v1OnaSay\n3i9bXP30u4YLIyMjsXXA/r4id4L+u/KEDgBCkNABQAgSOgAI4bSGbtPr0WFqynHUsZOqYee6Nq6L\nen+zpdejw9SU46hjJ1XDznVtXBf1/kI+ntABQAgSOgAIUeRyWJnfMKgkSgJ2aSZN5RA/LoZwxjm8\nzbOGLeqSKAnY/2fzpezg6LvGsEWBGLYIAAWGhA4AQpDQAUCInA5bTFq+1MwRTr7UzAHXeEIHACFI\n6AAgRF6WXIIO64s6+7S2ttZo27p1q4qXL19utA0MDBjHzc3NKv78+XOk69v9jjqMMa2rWWYSdFhf\n1NmnuSjV+F0/6jDGtK5mmSvjxo0zjs+fP6/iPXv2GG1Pnz41jjdv3qziV69eJdA7t3hCBwAhSOgA\nIAQJHQCEyMup/3HUlP2UlJQYxw0NDRlfa9dFOzo6VHzv3r2M70v6M4wmyR2LdC5WW0zTMMZcf4ZC\n3LGorKzMOO7r68v42jFjzGfYQ4cOqVj/+1faMPUfAAoMCR0AhHA6bDHNMzfHjx+v4t27d2d8nV0q\n8Su5TJs2LeN5og5N9Htdru5vmkoeUYUplfh93qhDE/1eJ+H+xm3SpEkqbm9vz2FP0oUndAAQgoQO\nAEKQ0AFAiNRO/U96I+jVq1cbxwsXLlTx7NmzI/dlzpw5Kn7x4oXR9vr1axX39/cHPmdQ+bBDU5o2\ngo7aF9fT7fN1h6Y46cMLPc/zqqqqVLxkyZLI562srFSxPaTx2bNnKn7w4EHka7jEEzoACEFCBwAh\nnM4UrampCXyxJFZU1F27ds049rsPfn0JM0xNX32xpaXFaLNXcQx6/ahyNaMwiRUVo3Lxf9/vcyR0\nfZEzRX///m0c//nzJ9J57LKK33n01Re3bNlitNmrNiaNmaIAUGBI6AAgBAkdAIRI7bDFJNTV1ak4\nTI22pqZGxXY9e9OmTcbx5cuXVTxhwgSjbeLEiSo+efKk0ZYvw6Ik8dv5J67dhRBdd3e3iu3ad1T2\nLmI/fvxQ8YwZM4y2WbNmqfjx48dGW3FxcSz9iRtP6AAgBAkdAIRwWnJxvalDeXm5cTxlyhQV2z+h\ng/6knj59unFsD3/89euXiru6uoy29evXZzyvPkTK/umXdrne1CEOo/Ul6sbMud6kOp8sW7bMONa/\nv/bwwqDDFltbW43ju3fvGseDg4MqXrlypdFWX1+f8bz79u1T8aVLlwL1xQWe0AFACBI6AAhBQgcA\nIcQNW9SHBup1Ls8zdyWy6/k7duxQsT206cmTJyq+c+eO0TY8PJyxL6Wlpcbx9+/f/9oXzzOnFt+6\ndcto04dI2VOgg0rjyotJcLEyYRK7ErnuS1rMnDlTxTdv3jTa9O+yH/3vT57neZ2dnSo+ffq00TY0\nNBT4PLW1tSrWd0jyPM9rbGxU8dixY422ixcvqlj/m5oLPKEDgBAkdAAQwulqi/bqbXoZIK4hjSUl\nJSrWN5v4S1+M476+PhX//PnTaNNnk2XjzZs3Kt62bVvG/tj/JseOHVPxx48fA1/Pr8zS1tYWZy3C\n6HDUIX6ZzvF/F0vZMEnXZY5R7k1erbZYVlamYv07aLNnivb09Kh469atRtunT59i6dvBgwdV3NTU\nlLE/9hDKuXPnqvjly5ex9IXVFgGgwJDQAUAIEjoACOF02KJfTdduC1pTt1+n19AbGhoyvm9gYMA4\nvnr1qoo3bNgQ6NphzZ8/P+P19ZXd/KRx+KFfTTdNQ/ySkvTfDOB5vb29xvGuXbtUHFfN3KYv3bF9\n+3ajbfHixYlcM1s8oQOAECR0ABAitTNF4xjS6Pcz9syZM5HOmY329nYV79+/32jzGwalz069cuVK\nQr1zI47yRNpQZomH3yYWS5cuddiT/9L/fey++fX11KlTKq6uro69X354QgcAIUjoACAECR0AhEht\nDV0XZkjj8uXLVRymtuliOGBFRYWK7V2J9Lq53e/bt29nfW37nrW1tWV9zmy5WClQep063/8OsXfv\nXhUH3YXIFX2HsQULFhhtel/tfus1dNd4QgcAIUjoACAECR0AhMiLGrrNb4y6XetyTd+JaOrUqUab\nXkP3s3HjRuPY3nVFp3/+MEsrpJHEMeq6MPV8/fMnsbRCWuh16lzQdyKaN2+e0Xb8+PFA57CXtHa9\nS5GOJ3QAEIKEDgBC5GXJJQ5JlSD0n5CrVq0y2vyGW+orxrW0tBhtX79+zfi+oJ8jjcMWkyBlmGLQ\nz5FvJZa0qa+vV/GBAwcCv09fLVXfYN7zPO/169dZ9ysqntABQAgSOgAIQUIHACGc1tD9ashRdyzK\ntbq6OuN4ypQpkc6zZs0aFV+4cCGrPv0r6JDGbPnVcfN9WF22kqjp+w1pLLT7G1Z3d7dxXF5eHuk8\nz58/V/HDhw+z6lOceEIHACFI6AAgRJHLn2hFRUWRLhamHHPu3DkVT548OePrmpqajOOamhoV27uR\nHD58OON54vrJq296mwT7no2MjMRZC4j0oV2vtmifX8IQx7/cs9g+VNTvaxj9/f0qLi0tzfi6devW\nZWyzd/GyZ2jr7O921BUei4uLI70vqqDfV57QAUAIEjoACEFCBwAhUltDjzrM7t27dyresmWLX1+M\nY7/74NeXqHXgnp4e4/jGjRuB3hdmOKdfv9va2nJSQ49at5a+m1GYz+fX7zj/NuKihn7kyBEVNzY2\nZnxdXLXvqOdpbW01jg8ePBjp+lFRQweAAkNCBwAhUlty0fmVDuwSxNGjR1V84sQJo62zs1Pvi9EW\n9D7YfbHP8+3bNxXr5R/PM1c4HBwcNNqGh4cDXT/MbFs/uSq56EYpHUR+bdx9cSHMbNtRzpNXJRd9\ns/RHjx4ZbfrmE0mVXD58+KDivr4+o622tlbF79+/N9qGhoYiXT8qSi4AUGBI6AAgBAkdAIRwWkOv\nqanJeLEkVldsaGgwjhctWqTit2/fGm1R74O+ZIDneV5HR4eKq6urjbaoQzGTuDeuaq2uhxvGdb24\n6vt+Evru5VUNXVdZWWkcV1VVqdhefiOuGvqhQ4dU3NzcHOmcLlBDB4ACQ0IHACFEl1xsesmjt7fX\naFuxYoWKKyoqjLb58+er+P79+0ab/XP77NmzKv7y5UukvvmJ6z7lc8nlL9ePdL2QwwFD9SnsNWK8\nT3lbcvGzdu1a41gfUqhvzO55ntfV1aVieyVG+99D36gil5s7j4aSCwAUGBI6AAhBQgcAIVJTQ7fF\nUStOcmPkf7mu/Ued+p/kjkVhaq35Mk0/TbX/kMM0RdbQCx01dAAoMCR0ABDin1x3IFsuyiphhCl7\nBBX0ffbr9L6k7T6NJterH9qSmJ0a9H1+M1NdbLSN/METOgAIQUIHACFI6AAgRGpq6C6G/+Wa69UW\n9fflqoZeCDVd16st6u9L298akFs8oQOAECR0ABAiNSUXuyQQdEak31C9uDZUDiOJMkcSQyFdCTOs\nzm/mZByzKrORRJnDxUYdKCw8oQOAECR0ABCChA4AQjhdbREAkBye0AFACBI6AAhBQgcAIUjoACAE\nCR0AhCChA4AQJHQAEIKEDgBCkNABQAgSOgAIQUIHACFI6AAgBAkdAIQgoQOAECR0ABCChA4AQpDQ\nAUAIEjoACEFCBwAhSOgAIAQJHQCEIKEDgBAkdAAQ4j8W/RkKxisfRAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f689232f950>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# demon a advesarial example\n",
    "img_rows = 28\n",
    "img_cols = 28;\n",
    "figure = pair_visual(np.reshape(adv_dataset[3],\n",
    "                                (img_rows, img_cols)),\n",
    "                     np.reshape(X_test[3],(img_rows, img_cols)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the accuracy for each datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval_params = {'batch_size': FLAGS.batch_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1134\n"
     ]
    }
   ],
   "source": [
    "# test the accuracy with G_11_adv training model\n",
    "accuracy_1_adv = model_eval(sess, x, y, predictions_1_adv, adv_dataset, adv_labels,\n",
    "                          args=eval_params)\n",
    "print(accuracy_1_adv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1509\n"
     ]
    }
   ],
   "source": [
    "# test the accuracy with G_10\n",
    "accuracy_0 = model_eval(sess, x, y, predictions_0, adv_dataset, adv_labels,\n",
    "                          args=eval_params)\n",
    "print(accuracy_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0451\n"
     ]
    }
   ],
   "source": [
    "# test the accuracy with G_11\n",
    "accuracy_1 = model_eval(sess, x, y, predictions_1, adv_dataset, adv_labels,\n",
    "                          args=eval_params)\n",
    "print(accuracy_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0796\n"
     ]
    }
   ],
   "source": [
    "# test the accuracy with G_12\n",
    "accuracy_2 = model_eval(sess, x, y, predictions_2, adv_dataset, adv_labels,\n",
    "                          args=eval_params)\n",
    "print(accuracy_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1569\n"
     ]
    }
   ],
   "source": [
    "# test the accuracy with G_13\n",
    "accuracy_3 = model_eval(sess, x, y, predictions_3, adv_dataset, adv_labels,\n",
    "                          args=eval_params)\n",
    "print(accuracy_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## looking at a specific example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model_eval_single(sess, x, y, model, X_test, args=None):\n",
    "    \"\"\"\n",
    "    Compute the accuracy of a TF model on some data\n",
    "    :param sess: TF session to use when training the graph\n",
    "    :param x: input placeholder\n",
    "    :param y: output placeholder (for labels)\n",
    "    :param model: model output predictions\n",
    "    :param X_test: numpy array with training inputs\n",
    "    :param Y_test: numpy array with training outputs\n",
    "    :param args: dict or argparse `Namespace` object.\n",
    "                 Should contain `batch_size`\n",
    "    :return: a float with the accuracy value\n",
    "    \"\"\"\n",
    "\n",
    "    # Define symbol for accuracy\n",
    "    # Keras 2.0 categorical_accuracy no longer calculates the mean internally\n",
    "    # tf.reduce_mean is called in here and is backward compatible with previous\n",
    "    # versions of Keras\n",
    "    acc_value = model\n",
    "\n",
    "\n",
    "    with sess.as_default():\n",
    "        cur_acc = acc_value.eval(\n",
    "            feed_dict={x: X_test,\n",
    "                       keras.backend.learning_phase(): 0})\n",
    "\n",
    "\n",
    "        # Divide by number of examples to get final value\n",
    "        accuracy = cur_acc\n",
    "\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.12515967  0.09121243  0.06959603  0.07286353  0.04800599  0.10128239\n",
      "   0.2864027   0.11342938  0.03099665  0.06105119]]\n",
      "[[ 0.92608136  0.00709069  0.01035078  0.00435896  0.006283    0.00825908\n",
      "   0.01454419  0.01002554  0.00480614  0.00820024]]\n",
      "[[ 0.19721605  0.0807325   0.0788397   0.07590845  0.09110018  0.12106974\n",
      "   0.08015344  0.12976149  0.07655197  0.06866659]]\n",
      "the prediction probability for adv_dataset the most likely label is: 6\n",
      "1.45441908389\n",
      "the prediction probability for test_dataset the most likely label is: 0\n",
      "92.6081359386\n",
      "the prediction probability for perturbation the most likely label is: 0\n",
      "92.6081359386\n",
      "the real label is: 0\n"
     ]
    }
   ],
   "source": [
    "# Test with G_10\n",
    "accuracy = model_eval_single(sess, x, y, predictions_0, adv_dataset[3:4], Y_test)\n",
    "accuracy2 = model_eval_single(sess, x, y, predictions_0, X_test[3:4], Y_test)\n",
    "accuracy3 = model_eval_single(sess, x, y, predictions_0, X_test[3:4]-adv_dataset[3:4], Y_test)\n",
    "print(accuracy)\n",
    "print(accuracy2)\n",
    "print(accuracy3)\n",
    "print('the prediction probability for adv_dataset the most likely label is:',np.argmax(accuracy))\n",
    "print(accuracy2[0][np.argmax(accuracy)]*100)\n",
    "print('the prediction probability for test_dataset the most likely label is:',np.argmax(accuracy2))\n",
    "print(accuracy2[0][np.argmax(accuracy2)]*100)\n",
    "print('the prediction probability for perturbation the most likely label is:',np.argmax(accuracy3))\n",
    "print(accuracy2[0][np.argmax(accuracy3)]*100)\n",
    "print('the real label is:', np.argmax(Y_test[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.09220058  0.08569479  0.0660625   0.12602471  0.05674984  0.13069081\n",
      "   0.22989927  0.11420287  0.03363661  0.06483797]]\n",
      "[[ 0.92498761  0.00880429  0.00600167  0.00411614  0.00751133  0.01012791\n",
      "   0.01449203  0.01081352  0.00498748  0.00815813]]\n",
      "[[ 0.2480381   0.08844792  0.13105106  0.04519266  0.08470612  0.08369339\n",
      "   0.08194591  0.08291218  0.07618802  0.07782459]]\n",
      "the prediction probability for adv_dataset the most likely label is: 6\n",
      "22.9899272323\n",
      "the prediction probability for test_dataset the most likely label is: 0\n",
      "92.4987614155\n",
      "the prediction probability for perturbation the most likely label is: 0\n",
      "24.8038098216\n",
      "the real label is: 0\n"
     ]
    }
   ],
   "source": [
    "# Test with G_11\n",
    "accuracy = model_eval_single(sess, x, y, predictions_1, adv_dataset[3:4], Y_test)\n",
    "accuracy2 = model_eval_single(sess, x, y, predictions_1, X_test[3:4], Y_test)\n",
    "accuracy3 = model_eval_single(sess, x, y, predictions_1, X_test[3:4]-adv_dataset[3:4], Y_test)\n",
    "print(accuracy)\n",
    "print(accuracy2)\n",
    "print(accuracy3)\n",
    "print('the prediction probability for adv_dataset the most likely label is:',np.argmax(accuracy))\n",
    "print(accuracy[0][np.argmax(accuracy)]*100)\n",
    "print('the prediction probability for test_dataset the most likely label is:',np.argmax(accuracy2))\n",
    "print(accuracy2[0][np.argmax(accuracy2)]*100)\n",
    "print('the prediction probability for perturbation the most likely label is:',np.argmax(accuracy3))\n",
    "print(accuracy3[0][np.argmax(accuracy3)]*100)\n",
    "print('the real label is:', np.argmax(Y_test[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.14347628  0.10451625  0.12610167  0.0969002   0.03008207  0.10205644\n",
      "   0.22418787  0.09217995  0.04678263  0.03371654]]\n",
      "[[ 0.93386215  0.0075681   0.00624246  0.00630635  0.00522392  0.00697231\n",
      "   0.0126106   0.00734279  0.00559903  0.00827237]]\n",
      "[[ 0.27558142  0.05211296  0.14025539  0.05801069  0.07654688  0.05254456\n",
      "   0.07801615  0.09081224  0.11870097  0.05741875]]\n",
      "the prediction probability for adv_dataset the most likely label is: 6\n",
      "1.26105956733\n",
      "the prediction probability for test_dataset the most likely label is: 0\n",
      "93.3862149715\n",
      "the prediction probability for perturbation the most likely label is: 0\n",
      "93.3862149715\n",
      "the real label is: 0\n"
     ]
    }
   ],
   "source": [
    "# Test with G_12\n",
    "accuracy = model_eval_single(sess, x, y, predictions_2, adv_dataset[3:4], Y_test)\n",
    "accuracy2 = model_eval_single(sess, x, y, predictions_2, X_test[3:4], Y_test)\n",
    "accuracy3 = model_eval_single(sess, x, y, predictions_2, X_test[3:4]-adv_dataset[3:4], Y_test)\n",
    "print(accuracy)\n",
    "print(accuracy2)\n",
    "print(accuracy3)\n",
    "print('the prediction probability for adv_dataset the most likely label is:',np.argmax(accuracy))\n",
    "print(accuracy[0][np.argmax(accuracy)]*100)\n",
    "print('the prediction probability for test_dataset the most likely label is:',np.argmax(accuracy2))\n",
    "print(accuracy2[0][np.argmax(accuracy2)]*100)\n",
    "print('the prediction probability for perturbation the most likely label is:',np.argmax(accuracy3))\n",
    "print(accuracy3[0][np.argmax(accuracy3)]*100)\n",
    "print('the real label is:', np.argmax(Y_test[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.17491305  0.09679463  0.08342385  0.06880189  0.0830973   0.10801172\n",
      "   0.20722389  0.07277342  0.07234329  0.03261693]]\n",
      "[[ 0.90227419  0.00928504  0.005565    0.01094813  0.00690311  0.00750446\n",
      "   0.02378539  0.00965154  0.00678511  0.01729812]]\n",
      "[[ 0.16267075  0.08566315  0.10499075  0.08561745  0.10983583  0.08588094\n",
      "   0.06753303  0.07732192  0.17179224  0.04869397]]\n",
      "the prediction probability for adv_dataset the most likely label is: 6\n",
      "2.37853862345\n",
      "the prediction probability for test_dataset the most likely label is: 0\n",
      "90.227419138\n",
      "the prediction probability for perturbation the most likely label is: 8\n",
      "0.678510824218\n",
      "the real label is: 0\n"
     ]
    }
   ],
   "source": [
    "# Test with G_13\n",
    "accuracy = model_eval_single(sess, x, y, predictions_3, adv_dataset[3:4], Y_test)\n",
    "accuracy2 = model_eval_single(sess, x, y, predictions_3, X_test[3:4], Y_test)\n",
    "accuracy3 = model_eval_single(sess, x, y, predictions_3, X_test[3:4]-adv_dataset[3:4], Y_test)\n",
    "print(accuracy)\n",
    "print(accuracy2)\n",
    "print(accuracy3)\n",
    "print('the prediction probability for adv_dataset the most likely label is:',np.argmax(accuracy))\n",
    "print(accuracy[0][np.argmax(accuracy)]*100)\n",
    "print('the prediction probability for test_dataset the most likely label is:',np.argmax(accuracy2))\n",
    "print(accuracy2[0][np.argmax(accuracy2)]*100)\n",
    "print('the prediction probability for perturbation the most likely label is:',np.argmax(accuracy3))\n",
    "print(accuracy3[0][np.argmax(accuracy3)]*100)\n",
    "print('the real label is:', np.argmax(Y_test[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "accuracy = model_eval_single(sess, x, y, predictions_1, X_test[0:3], Y_test)\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test the jsma advesarial examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The advesarial examples are generated in JSMA_ADV with G_11 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set (10, 10, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "from six.moves import cPickle as pickle\n",
    "pickle_file = 'adv_jsma_G11.pickle'\n",
    "\n",
    "with open(pickle_file, 'rb') as f:\n",
    "    save = pickle.load(f)\n",
    "    adv_dataset_jsma = save['adv_dataset']\n",
    "    del save  # hint to help gc free up memory\n",
    "    print('Test set', adv_dataset_jsma.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test this with G_10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.33811024  0.08834214  0.076858    0.06403018  0.06661663  0.09679699\n",
      "   0.10296302  0.06826112  0.03669453  0.06132723]]\n",
      "the prediction probability for the most likely label is: 0\n",
      "33.8110238314\n"
     ]
    }
   ],
   "source": [
    "inp = adv_dataset_jsma[4][0]\n",
    "inp = np.reshape(inp, (1,28,28,1))\n",
    "accuracy = model_eval_single(sess, x, y, predictions_0, inp, Y_test)\n",
    "print(accuracy)\n",
    "print('the prediction probability for the most likely label is:',np.argmax(accuracy))\n",
    "print(accuracy[0][np.argmax(accuracy)]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test this with G_11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.26828858  0.08265281  0.0418817   0.03990842  0.31441119  0.07412048\n",
      "   0.06465629  0.03284422  0.03423857  0.0469977 ]]\n",
      "the prediction probability for the most likely label is: 4\n",
      "31.4411193132\n"
     ]
    }
   ],
   "source": [
    "inp = adv_dataset_jsma[4][0]\n",
    "inp = np.reshape(inp, (1,28,28,1))\n",
    "accuracy = model_eval_single(sess, x, y, predictions_1, inp, Y_test)\n",
    "print(accuracy)\n",
    "print('the prediction probability for the most likely label is:',np.argmax(accuracy))\n",
    "print(accuracy[0][np.argmax(accuracy)]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test this with G_12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.32105622  0.03599932  0.04024804  0.07350036  0.25461677  0.04621547\n",
      "   0.07224196  0.04551077  0.03321132  0.0773998 ]]\n",
      "the prediction probability for the most likely label is: 0\n",
      "32.1056216955\n"
     ]
    }
   ],
   "source": [
    "inp = adv_dataset_jsma[4][0]\n",
    "inp = np.reshape(inp, (1,28,28,1))\n",
    "accuracy = model_eval_single(sess, x, y, predictions_2, inp, Y_test)\n",
    "print(accuracy)\n",
    "print('the prediction probability for the most likely label is:',np.argmax(accuracy))\n",
    "print(accuracy[0][np.argmax(accuracy)]*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test this with G_13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.39604717  0.05819289  0.04191756  0.06817655  0.13346361  0.04841193\n",
      "   0.09676099  0.03589516  0.06251854  0.05861561]]\n",
      "the prediction probability for the most likely label is: 0\n",
      "39.6047174931\n"
     ]
    }
   ],
   "source": [
    "inp = adv_dataset_jsma[4][0]\n",
    "inp = np.reshape(inp, (1,28,28,1))\n",
    "accuracy = model_eval_single(sess, x, y, predictions_3, inp, Y_test)\n",
    "print(accuracy)\n",
    "print('the prediction probability for the most likely label is:',np.argmax(accuracy))\n",
    "print(accuracy[0][np.argmax(accuracy)]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
